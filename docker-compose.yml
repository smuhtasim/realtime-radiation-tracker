services:
  kafka:
    image: apache/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_KRAFT_CLUSTER_ID: abcd
    volumes:
      - ./dataset:/data
      - kafka-data:/var/lib/kafka
    networks:
      - kafka-net

  redis:
    image: redis:7.0-alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - kafka-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: producer
    depends_on:
      - kafka
    networks:
      - kafka-net
    volumes:
      - ./dataset:/data  

  flink-jobmanager:
    image: flink:1.17
    container_name: jobmanager
    ports:
      - "8081:8081"
    command: jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    networks:
      - kafka-net
    volumes:
      - ./pyflink_job/jars:/opt/flink/usrlib

  flink-taskmanager:
    image: flink:1.17
    container_name: taskmanager
    command: taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=jobmanager
    networks:
      - kafka-net
    volumes:
      - ./pyflink_job/jars:/opt/flink/usrlib

  pyflink-job:
    build:
      context: ./pyflink_job
      dockerfile: Dockerfile
    container_name: pyflink-job
    depends_on:
      - kafka
      - flink-jobmanager
    environment:
      - PYFLINK_CLIENT_EXECUTION_MODE=remote
      - PYFLINK_CLIENT_REMOTE_HOST=jobmanager
    networks:
      - kafka-net
    volumes:
      - ./pyflink_job:/opt/pyflink_job
      - ./pyflink_job/jars:/opt/flink/usrlib
    working_dir: /opt/pyflink_job
    command: ["python3", "job.py"]

  backend:
    build: ./backend
    container_name: backend
    ports:
      - "8000:8000"
    depends_on:
      - kafka
      - redis
    networks:
      - kafka-net
  
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:80"  
    depends_on:
      - backend
    networks:
      - kafka-net
volumes:
  kafka-data:

networks:
  kafka-net:
